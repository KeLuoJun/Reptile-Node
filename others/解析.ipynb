{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对比总结\n",
    "\n",
    "| 特性                | XPath               | JSONPath            | BeautifulSoup          |\n",
    "|---------------------|---------------------|---------------------|------------------------|\n",
    "| **数据格式**         | HTML/XML           | JSON               | HTML/XML              |\n",
    "| **语法复杂度**       | 高（需学习路径表达式） | 中（类似XPath）     | 低（Pythonic API）     |\n",
    "| **性能**             | 高（配合`lxml`）    | 中                  | 中/低（依赖解析器）     |\n",
    "| **容错性**           | 低                 | -（JSON本身结构化） | 高（自动修复HTML）     |\n",
    "| **典型使用场景**     | 精准提取复杂HTML元素 | 提取多层嵌套JSON数据 | 快速解析不规范HTML     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xpath基本语法：  \n",
    "1.路径查询  \n",
    "//：查找所有子孙节点，不考虑层级关系  \n",
    "/ ：找直接子节点  \n",
    "2.谓词查询  \n",
    "//div[@id]  \n",
    "//div[@id=\"maincontent\"]  \n",
    "3.属性查询  \n",
    "//@class  \n",
    "4.模糊查询  \n",
    "//div[contains(@id, \"he\")]  \n",
    "//div[starts‐with(@id, \"he\")]  \n",
    "5.内容查询  \n",
    "//div/h1/text()  \n",
    "6.逻辑运算  \n",
    "//div[@id=\"head\" and @class=\"s_down\"]  \n",
    "//title | //price  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取百度网站的百度一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "百度一下\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from lxml import etree\n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "url = \"https://www.baidu.com/\"\n",
    "\n",
    "headers = {\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, likeGecko) Chrome/74.0.3729.169 Safari/537.36'\n",
    "}\n",
    "\n",
    "request = Request(url, headers=headers)\n",
    "response = urlopen(request)\n",
    "content = response.read().decode('utf-8')\n",
    "\n",
    "tree = etree.HTML(content)\n",
    "result = tree.xpath(\"//input[@id='su']/@value\")[0]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 案例：站长图片素材下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "def create_request(page):\n",
    "    if page == 1:\n",
    "        url = \"https://sc.chinaz.com/tupian/hefumeinv_2.html\"\n",
    "    else:\n",
    "        url = \"https://sc.chinaz.com/tupian/hefumeinv_{}.html\".format(page)\n",
    "\n",
    "    headers = {\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, likeGecko) Chrome/74.0.3729.169 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    request = Request(url, headers=headers)\n",
    "    return request\n",
    "\n",
    "def get_content(request):\n",
    "    response = urlopen(request)\n",
    "    content = response.read().decode('utf-8')\n",
    "    return content\n",
    "\n",
    "def down_load(content):\n",
    "    tree = etree.HTML(content)\n",
    "    img_src = tree.xpath(\"//div[contains(@class, 'tupian-list com-img-txt-list')]/div[contains(@class, 'item')]/img/@data-original\")\n",
    "    img_name = tree.xpath(\"//div[contains(@class, 'tupian-list com-img-txt-list')]/div[contains(@class, 'item')]/img/@alt\")\n",
    "\n",
    "    for i in range(len(img_src)):\n",
    "        name = img_name[i]\n",
    "        img_url = img_src[i]  # 此时图片的url少了http协议\n",
    "        img_url = 'https:' + img_url\n",
    "\n",
    "        # 下载图片\n",
    "        urlretrieve(url=img_url, filename='../data/imgs/' + name + '.jpg')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_page = int(input('请输入起始页码：'))\n",
    "    end_page = int(input('请输入结束页码：'))\n",
    "\n",
    "    for page in range(start_page, end_page + 1):\n",
    "        request = create_request(page)\n",
    "        content = get_content(request)\n",
    "        down_load(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jsonpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jsonpath练习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'category': '修真', 'author': '六道', 'title': '坏蛋是怎样练成的', 'price': 8.95},\n",
       " {'category': '修真',\n",
       "  'author': '唐家三少',\n",
       "  'title': '斗罗大陆',\n",
       "  'isbn': '0-553-21311-3',\n",
       "  'price': 8.99}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 教程链接：https://blog.csdn.net/luxideyao/article/details/77802389 \n",
    "import json\n",
    "import jsonpath\n",
    "\n",
    "with open('../data/jsonpath_example.json', 'r', encoding='utf-8') as f:\n",
    "    obj = json.load(f)\n",
    "\n",
    "# 书店所有书的作者\n",
    "author_list = jsonpath.jsonpath(obj, '$.store.book[*].author')\n",
    "author_list\n",
    "\n",
    "# 所有作者\n",
    "authors = jsonpath.jsonpath(obj, '$..author')\n",
    "authors\n",
    "\n",
    "# store下面的所有元素   \n",
    "tag_list = jsonpath.jsonpath(obj, '$.store.*')\n",
    "tag_list\n",
    "\n",
    "# store下面的所有price\n",
    "price_list = jsonpath.jsonpath(obj, '$.store..price')\n",
    "price_list\n",
    "\n",
    "# 最后有一本书\n",
    "last_book = jsonpath.jsonpath(obj, '$..book[(@.length-1)]')\n",
    "last_book\n",
    "\n",
    "# 过滤出所有的包含isbn的书\n",
    "isbn_list = jsonpath.jsonpath(obj, '$..book[?(@.isbn)]')\n",
    "isbn_list\n",
    "\n",
    "# 过滤出价格低于10的书\n",
    "low_price_list = jsonpath.jsonpath(obj, '$..book[?(@.price<10)]')\n",
    "low_price_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 案例：淘票票"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['阿坝',\n",
       " '阿克苏',\n",
       " '阿拉尔',\n",
       " '阿拉善',\n",
       " '阿勒泰',\n",
       " '安康',\n",
       " '安庆',\n",
       " '鞍山',\n",
       " '安顺',\n",
       " '安阳',\n",
       " '白城',\n",
       " '百色',\n",
       " '白沙',\n",
       " '白山',\n",
       " '白银',\n",
       " '保定',\n",
       " '宝鸡',\n",
       " '保山',\n",
       " '保亭自治县',\n",
       " '包头',\n",
       " '巴彦淖尔',\n",
       " '巴中',\n",
       " '北海',\n",
       " '北京',\n",
       " '蚌埠',\n",
       " '本溪',\n",
       " '毕节',\n",
       " '滨州',\n",
       " '亳州',\n",
       " '巴音郭楞',\n",
       " '沧州',\n",
       " '长春',\n",
       " '常德',\n",
       " '昌吉',\n",
       " '昌江',\n",
       " '长沙',\n",
       " '长治',\n",
       " '常州',\n",
       " '巢湖市',\n",
       " '朝阳',\n",
       " '潮州',\n",
       " '承德',\n",
       " '成都',\n",
       " '澄迈县',\n",
       " '郴州',\n",
       " '赤峰',\n",
       " '池州',\n",
       " '重庆',\n",
       " '崇左',\n",
       " '楚雄',\n",
       " '滁州',\n",
       " '大理',\n",
       " '大连',\n",
       " '儋州',\n",
       " '丹东',\n",
       " '大庆',\n",
       " '大同',\n",
       " '大兴安岭',\n",
       " '达州',\n",
       " '屯昌',\n",
       " '德宏',\n",
       " '德阳',\n",
       " '德州',\n",
       " '定安',\n",
       " '定西',\n",
       " '迪庆',\n",
       " '东方',\n",
       " '东莞',\n",
       " '东营',\n",
       " '鄂尔多斯',\n",
       " '恩施',\n",
       " '鄂州',\n",
       " '防城港',\n",
       " '佛山',\n",
       " '抚顺',\n",
       " '阜新',\n",
       " '阜阳',\n",
       " '抚州',\n",
       " '福州',\n",
       " '甘南',\n",
       " '赣州',\n",
       " '甘孜',\n",
       " '巩义市',\n",
       " '广安',\n",
       " '广元',\n",
       " '广州',\n",
       " '贵港',\n",
       " '桂林',\n",
       " '贵阳',\n",
       " '固原',\n",
       " '哈尔滨',\n",
       " '海北',\n",
       " '海东',\n",
       " '海口',\n",
       " '海南州',\n",
       " '海西',\n",
       " '哈密',\n",
       " '韩城市',\n",
       " '邯郸',\n",
       " '杭州',\n",
       " '汉中',\n",
       " '鹤壁',\n",
       " '河池',\n",
       " '合肥',\n",
       " '鹤岗',\n",
       " '黑河',\n",
       " '衡水',\n",
       " '衡阳',\n",
       " '和田',\n",
       " '河源',\n",
       " '菏泽',\n",
       " '贺州',\n",
       " '红河',\n",
       " '淮安',\n",
       " '淮北',\n",
       " '怀化',\n",
       " '淮南',\n",
       " '黄冈',\n",
       " '黄南',\n",
       " '黄山',\n",
       " '黄石',\n",
       " '呼和浩特',\n",
       " '惠州',\n",
       " '葫芦岛',\n",
       " '呼伦贝尔',\n",
       " '湖州',\n",
       " '佳木斯',\n",
       " '吉安',\n",
       " '江门',\n",
       " '焦作',\n",
       " '嘉兴',\n",
       " '嘉峪关',\n",
       " '揭阳',\n",
       " '吉林',\n",
       " '济南',\n",
       " '金昌',\n",
       " '晋城',\n",
       " '景德镇',\n",
       " '荆门',\n",
       " '荆州',\n",
       " '金华',\n",
       " '济宁',\n",
       " '晋中',\n",
       " '锦州',\n",
       " '九江',\n",
       " '酒泉',\n",
       " '鸡西',\n",
       " '济源',\n",
       " '开封',\n",
       " '喀什',\n",
       " '克拉玛依',\n",
       " '克孜勒苏柯尔克孜',\n",
       " '昆明',\n",
       " '来宾',\n",
       " '廊坊',\n",
       " '兰州',\n",
       " '拉萨',\n",
       " '乐东',\n",
       " '乐山',\n",
       " '凉山',\n",
       " '连云港',\n",
       " '聊城',\n",
       " '辽阳',\n",
       " '辽源',\n",
       " '丽江',\n",
       " '临沧',\n",
       " '临汾',\n",
       " '临高',\n",
       " '临夏',\n",
       " '临沂',\n",
       " '林芝',\n",
       " '丽水',\n",
       " '六安',\n",
       " '六盘水',\n",
       " '柳州',\n",
       " '陇南',\n",
       " '龙岩',\n",
       " '娄底',\n",
       " '陵水',\n",
       " '吕梁',\n",
       " '漯河',\n",
       " '洛阳',\n",
       " '泸州',\n",
       " '马鞍山',\n",
       " '茂名',\n",
       " '眉山',\n",
       " '梅州',\n",
       " '绵阳',\n",
       " '牡丹江',\n",
       " '南昌',\n",
       " '南充',\n",
       " '南京',\n",
       " '南宁',\n",
       " '南平',\n",
       " '南通',\n",
       " '南阳',\n",
       " '那曲',\n",
       " '内江',\n",
       " '宁波',\n",
       " '宁德',\n",
       " '怒江',\n",
       " '盘锦',\n",
       " '攀枝花',\n",
       " '平顶山',\n",
       " '平凉',\n",
       " '萍乡',\n",
       " '普洱',\n",
       " '莆田',\n",
       " '濮阳',\n",
       " '黔东南',\n",
       " '潜江',\n",
       " '黔南',\n",
       " '黔西南',\n",
       " '青岛',\n",
       " '庆阳',\n",
       " '清远',\n",
       " '秦皇岛',\n",
       " '钦州',\n",
       " '琼海',\n",
       " '琼中',\n",
       " '齐齐哈尔',\n",
       " '七台河',\n",
       " '泉州',\n",
       " '曲靖',\n",
       " '衢州',\n",
       " '日喀则',\n",
       " '日照',\n",
       " '三门峡',\n",
       " '三明',\n",
       " '三亚',\n",
       " '上海',\n",
       " '商洛',\n",
       " '商丘',\n",
       " '上饶',\n",
       " '山南',\n",
       " '汕头',\n",
       " '汕尾',\n",
       " '韶关',\n",
       " '绍兴',\n",
       " '邵阳',\n",
       " '神农架林区',\n",
       " '沈阳',\n",
       " '深圳',\n",
       " '石河子',\n",
       " '石家庄',\n",
       " '十堰',\n",
       " '石嘴山',\n",
       " '双鸭山',\n",
       " '朔州',\n",
       " '四平',\n",
       " '松原',\n",
       " '绥化',\n",
       " '遂宁',\n",
       " '随州',\n",
       " '宿迁',\n",
       " '宿州',\n",
       " '苏州',\n",
       " '塔城',\n",
       " '泰安',\n",
       " '太原',\n",
       " '台州',\n",
       " '泰州',\n",
       " '唐山',\n",
       " '天津',\n",
       " '天门',\n",
       " '天水',\n",
       " '铁岭',\n",
       " '铜川',\n",
       " '通化',\n",
       " '通辽',\n",
       " '铜陵',\n",
       " '铜仁',\n",
       " '图木舒克市',\n",
       " '万宁',\n",
       " '潍坊',\n",
       " '威海',\n",
       " '渭南',\n",
       " '文昌',\n",
       " '文山',\n",
       " '温州',\n",
       " '乌海',\n",
       " '武汉',\n",
       " '芜湖',\n",
       " '五家渠',\n",
       " '乌兰察布',\n",
       " '乌鲁木齐',\n",
       " '武威',\n",
       " '无锡',\n",
       " '五指山市',\n",
       " '吴忠',\n",
       " '梧州',\n",
       " '厦门',\n",
       " '西安',\n",
       " '湘潭',\n",
       " '湘西',\n",
       " '襄阳',\n",
       " '咸宁',\n",
       " '仙桃',\n",
       " '咸阳',\n",
       " '孝感',\n",
       " '锡林郭勒',\n",
       " '兴安盟',\n",
       " '邢台',\n",
       " '兴义市',\n",
       " '西宁',\n",
       " '新乡',\n",
       " '信阳',\n",
       " '新余',\n",
       " '忻州',\n",
       " '西双版纳',\n",
       " '宣城',\n",
       " '许昌',\n",
       " '徐州',\n",
       " '雅安',\n",
       " '延安',\n",
       " '延边',\n",
       " '盐城',\n",
       " '阳江',\n",
       " '阳泉',\n",
       " '扬州',\n",
       " '烟台',\n",
       " '宜宾',\n",
       " '宜昌',\n",
       " '伊春',\n",
       " '宜春',\n",
       " '伊犁',\n",
       " '银川',\n",
       " '营口',\n",
       " '鹰潭',\n",
       " '宜兴市',\n",
       " '益阳',\n",
       " '永州',\n",
       " '岳阳',\n",
       " '玉林',\n",
       " '榆林',\n",
       " '运城',\n",
       " '云浮',\n",
       " '玉树',\n",
       " '玉溪',\n",
       " '枣庄',\n",
       " '张家界',\n",
       " '张家口',\n",
       " '张掖',\n",
       " '漳州',\n",
       " '湛江',\n",
       " '肇庆',\n",
       " '昭通',\n",
       " '郑州',\n",
       " '镇江',\n",
       " '中山',\n",
       " '中卫',\n",
       " '周口',\n",
       " '舟山',\n",
       " '珠海',\n",
       " '驻马店',\n",
       " '株洲',\n",
       " '淄博',\n",
       " '自贡',\n",
       " '资阳',\n",
       " '遵义']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "url = \"https://dianying.taobao.com/cityAction.json?activityId&_ksTS=1739379951943_108&jsoncallback=jsonp109&action=cityAction&n_s=new&event_submit_doGetAllRegion=true\"\n",
    "\n",
    "\n",
    "headers = {\n",
    "    \"content-encoding\": \"gzip\",\n",
    "    \"content-language\": \"zh-CN\",\n",
    "    \"content-type\": \"text/html;charset=UTF-8\",\n",
    "    \"date\": \"Wed, 12 Feb 2025 17:05:51 GMT\",\n",
    "    \"eagleeye-traceid\": \"2150434017393799518416169e00ec\",\n",
    "    \"s\": \"STATUS_NOT_EXISTED\",\n",
    "    \"server\": \"Tengine/Aserver\",\n",
    "    \"strict-transport-security\": \"max-age=31536000\",\n",
    "    \"timing-allow-origin\": \"*\",\n",
    "    \"vary\": \"Accept-Encoding\",\n",
    "    # \":authority\": \"dianying.taobao.com\",\n",
    "    # \":method\": \"GET\",\n",
    "    # \":path\": \"/cityAction.json?activityId&_ksTS=1739379951943_108&jsoncallback=jsonp109&action=cityAction&n_s=new&event_submit_doGetAllRegion=true\",\n",
    "    # \":scheme\": \"https\",\n",
    "    \"accept\": \"text/javascript, application/javascript, application/ecmascript, application/x-ecmascript, */*; q=0.01\",\n",
    "    # \"accept-encoding\": \"gzip, deflate, br, zstd\",\n",
    "    \"accept-language\": \"zh,zh-CN;q=0.9\",\n",
    "    \"bx-v\": \"2.5.28\",\n",
    "    \"cookie\": \"t=41f6894a466c20b2deeb5ec943460b60; cookie2=13a28f469ddc88e8e87e8e7d6600a54c; v=0; _tb_token_=e85537438eab4; xlly_s=1; isg=BJCQTRj5w7-Swp-77reSMcPdYd7iWXSj6XNrwYpjk-u-xTFvMmxdMev7nYUlECx7\",\n",
    "    \"priority\": \"u=1, i\",\n",
    "    \"referer\": \"https://dianying.taobao.com/\",\n",
    "    \"sec-ch-ua\": \"\\\"Not(A:Brand\\\";v=\\\"99\\\", \\\"Google Chrome\\\";v=\\\"133\\\", \\\"Chromium\\\";v=\\\"133\\\"\",\n",
    "    \"sec-ch-ua-mobile\": \"?0\",\n",
    "    \"sec-ch-ua-platform\": \"\\\"Windows\\\"\",\n",
    "    \"sec-fetch-dest\": \"empty\",\n",
    "    \"sec-fetch-mode\": \"cors\",\n",
    "    \"sec-fetch-site\": \"same-origin\",\n",
    "    \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36\",\n",
    "    \"x-requested-with\": \"XMLHttpRequest\"\n",
    "}\n",
    "\n",
    "request = Request(url, headers=headers)\n",
    "response = urlopen(request)\n",
    "content = response.read().decode('utf-8')\n",
    "match = re.search('\\(([^)]+)\\)', content)\n",
    "content = match.group(1)\n",
    "\n",
    "with open('../data/taopiaopiao.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(content)\n",
    "\n",
    "with open('../data/taopiaopiao.json', 'r', encoding='utf-8') as f:\n",
    "    obj = json.load(f)\n",
    "\n",
    "city_list = jsonpath.jsonpath(obj, \"$..regionName\")\n",
    "city_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p1']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "with open('../data/bs4_example.html', 'r', encoding='utf-8') as f:\n",
    "    soup = BeautifulSoup(f, 'lxml')\n",
    "\n",
    "# 根据标签名查找节点（找到的是第一个符合条件的数据）\n",
    "soup.a\n",
    "# 获取标签的属性和属性值\n",
    "soup.a.attrs\n",
    "\n",
    "# bs4 的一些函数\n",
    "# (1) find()  返回第一个符合条件的数据\n",
    "soup.find('a')\n",
    "soup.find('a', title='a2')\n",
    "soup.find('a', class_='a1')  # 根据class 属性查找，class需要加上下划线\n",
    "\n",
    "# (2) find_all()  返回所有符合条件的数据，列表形式返回\n",
    "soup.find_all('a')  \n",
    "soup.find_all(['a', 'span'])  # 获取多个标签数据，参数为列表\n",
    "soup.find_all('li', limit=2)  # 查找前2个li标签\n",
    "\n",
    "# (3) select()  推荐\n",
    "soup.select('a')\n",
    "soup.select('.a1')  # 根据class属性查找(.class)\n",
    "soup.select('#l1')  # 根据id属性查找(#id)\n",
    "\n",
    "\n",
    "# 属性选择器（通过属性来查找对应的标签）\n",
    "soup.select('li[id]')  # 查找到li标签中有id的标签\n",
    "soup.select('li[id=\"l1\"]')  # 查找到id为l1的li标签\n",
    "\n",
    "\n",
    "# 层级选择起\n",
    "soup.select('div li')  # 后代选择器（找到的是div下面的li）\n",
    "soup.select('div > ul > li')  # 子选择器（找到的是div下的直接子标签li）\n",
    "\n",
    "soup.select('a, li')  # 获取多个标签数据\n",
    "\n",
    "\n",
    "# 节点信息（获取节点内容）\n",
    "obj = soup.select('#d1')[0]\n",
    "obj.string  # 只适用于标签中只有内容，没有嵌套其他标签\n",
    "obj.get_text()  # 适用于标签中只有内容或包含嵌套标签（推荐）\n",
    "\n",
    "# 节点属性\n",
    "obj = soup.select('#p1')[0]\n",
    "obj.name  # 获取标签名\n",
    "obj.attrs # 将属性值作为字典返回\n",
    "\n",
    "# 获取节点的属性\n",
    "obj = soup.select('#p1')[0]\n",
    "obj.attrs.get('class')  # 推荐\n",
    "obj.get('class')\n",
    "obj['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 案例：证券之星主页板块名称下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['・农林牧渔业',\n",
       " '・采矿业',\n",
       " '・制造业',\n",
       " '・水电煤',\n",
       " '・建筑业',\n",
       " '・批发和零售业',\n",
       " '・交通运输仓储',\n",
       " '・住宿和餐饮业',\n",
       " '・信息技术业',\n",
       " '・金融业',\n",
       " '・房地产业',\n",
       " '・租赁商务服务业',\n",
       " '・科学技术服务业',\n",
       " '・公共设施管理业',\n",
       " '・居民服务修理业',\n",
       " '・教育',\n",
       " '・卫生和社会工作',\n",
       " '・文化体育娱乐业',\n",
       " '・综合']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "\n",
    "url = \"https://quote.stockstar.com/\"\n",
    "\n",
    "headers = {\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, likeGecko) Chrome/74.0.3729.169 Safari/537.36'\n",
    "    }\n",
    "\n",
    "req = Request(url, headers=headers)\n",
    "response = urlopen(req)\n",
    "content = response.read().decode('gb2312')\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(content, 'lxml')\n",
    "\n",
    "# xpath路径：//li/a[starts-with(@href, '/stock/industry_')]\n",
    "# [attr=value] 选择 attr 属性值等于 value 的元素\n",
    "# [attr*=value] 选择 attr 属性值包含 value 的元素\n",
    "# [attr$=value] 选择 attr 属性值以 value 结尾的元素\n",
    "# [attr~=value] 选择 attr 属性值包含单词 value 的元素（以空格分隔）\n",
    "# [attr^=value] 选择 attr 属性值以 value 开头的元素（以连字符分隔）\n",
    "name_list = soup.select('li a[href^=\"/stock/industry_\"]')\n",
    "name_list = [name.get_text() for name in name_list]\n",
    "name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
